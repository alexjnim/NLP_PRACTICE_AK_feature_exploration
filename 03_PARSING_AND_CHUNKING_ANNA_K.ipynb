{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHUNKING\n",
    "\n",
    "Shallow parsing, also known as light parsing or chunking, is a technique of analyzing the structure of a sentence to break it down into its smallest constituents, which are tokens like words, and group them together into higher-level phrases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import requests\n",
    "data = requests.get('http://www.gutenberg.org/files/1399/1399-h/1399-h.htm')\n",
    "content = data.content\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in sample_text: 5 \n",
      "\n",
      "Sample text sentences : \n",
      " ['Happy families are all alike; every unhappy family is unhappy in its own way.'\n",
      " 'Everything was in confusion in the Oblonskysâ€™ house.'\n",
      " 'The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him.'\n",
      " 'This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it.'\n",
      " 'Every person in the house felt that there was no sense in their living together, and that the stray people brought together by chance in any inn had more in common with one another than they, the members of the family and household of the Oblonskys.']\n"
     ]
    }
   ],
   "source": [
    "clean_content = strip_html_tags(content)\n",
    "sample_text = clean_content[1932:2721]\n",
    "sample_text2 = sample_text.replace(\"\\n\", \" \")\n",
    "sample_text2\n",
    "\n",
    "### remove \\n from text\n",
    "sample_text2 = sample_text.replace(\"\\n\", \" \")\n",
    "\n",
    "SENTENCE_TOKENS_PATTERN = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = nltk.tokenize.RegexpTokenizer(\n",
    "            pattern=SENTENCE_TOKENS_PATTERN,\n",
    "            gaps=True)\n",
    "sample_sentences = regex_st.tokenize(sample_text2)\n",
    "print('Total sentences in sample_text:', len(sample_sentences), '\\n')\n",
    "print('Sample text sentences : \\n', np.array(sample_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
