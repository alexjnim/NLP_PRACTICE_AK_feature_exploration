{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text syntax and structure processing\n",
    "\n",
    "Knowledge about the structure and syntax of language is helpful in many areas like text processing, annotation, and parsing for further operations such as text classification or summarization. In this section, we implement some of the concepts and techniques used to understand text syntax and structure. This is extremely useful in natural language processing and is usually done after text processing and wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "data = requests.get('http://www.gutenberg.org/files/1399/1399-h/1399-h.htm')\n",
    "content = data.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it. Every person in the house felt that there was no sense in their living together, and that the stray people brought together by chance in any inn had more in common with one another than they, the members of the family and household of the Oblonskys.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_content = strip_html_tags(content)\n",
    "sample_text = clean_content[1932:2721]\n",
    "sample_text2 = sample_text.replace(\"\\n\", \" \")\n",
    "sample_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in sample_text: 5 \n",
      "\n",
      "Sample text sentences : \n",
      " ['Happy families are all alike; every unhappy family is unhappy in its own way.'\n",
      " 'Everything was in confusion in the Oblonskys’ house.'\n",
      " 'The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him.'\n",
      " 'This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it.'\n",
      " 'Every person in the house felt that there was no sense in their living together, and that the stray people brought together by chance in any inn had more in common with one another than they, the members of the family and household of the Oblonskys.']\n"
     ]
    }
   ],
   "source": [
    "### remove \\n from text\n",
    "sample_text2 = sample_text.replace(\"\\n\", \" \")\n",
    "\n",
    "SENTENCE_TOKENS_PATTERN = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = nltk.tokenize.RegexpTokenizer(\n",
    "            pattern=SENTENCE_TOKENS_PATTERN,\n",
    "            gaps=True)\n",
    "sample_sentences = regex_st.tokenize(sample_text2)\n",
    "print('Total sentences in sample_text:', len(sample_sentences), '\\n')\n",
    "print('Sample text sentences : \\n', np.array(sample_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### default nltk and spacy POS taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "sentence = \"US unveils world's most powerful supercomputer, beats China.\"\n",
    "nlp = spacy.load('en', parse=True, tag=True, entity=True)\n",
    "\n",
    "def spacy_POS_tag(sentence):\n",
    "    sentence_nlp = nlp(sentence)\n",
    "    # POS tagging with Spacy\n",
    "    spacy_pos_tagged = [(word, word.tag_, word.pos_) for word in sentence_nlp]\n",
    "    return pd.DataFrame(spacy_pos_tagged, columns=['Word', 'POS tag', 'Tag type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>US</td>\n",
       "      <td>unveils</td>\n",
       "      <td>world</td>\n",
       "      <td>'s</td>\n",
       "      <td>most</td>\n",
       "      <td>powerful</td>\n",
       "      <td>supercomputer</td>\n",
       "      <td>,</td>\n",
       "      <td>beats</td>\n",
       "      <td>China</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>NN</td>\n",
       "      <td>POS</td>\n",
       "      <td>RBS</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>,</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>NNP</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag type</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PART</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1      2     3     4         5              6      7  \\\n",
       "Word         US  unveils  world    's  most  powerful  supercomputer      ,   \n",
       "POS tag     NNP      VBZ     NN   POS   RBS        JJ             NN      ,   \n",
       "Tag type  PROPN     VERB   NOUN  PART   ADV       ADJ           NOUN  PUNCT   \n",
       "\n",
       "              8      9     10  \n",
       "Word      beats  China      .  \n",
       "POS tag     VBZ    NNP      .  \n",
       "Tag type   VERB  PROPN  PUNCT  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_POS_tag(sentence).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy families are all alike; every unhappy family is unhappy in its own way.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Happy</td>\n",
       "      <td>families</td>\n",
       "      <td>are</td>\n",
       "      <td>all</td>\n",
       "      <td>alike</td>\n",
       "      <td>;</td>\n",
       "      <td>every</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>family</td>\n",
       "      <td>is</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>in</td>\n",
       "      <td>its</td>\n",
       "      <td>own</td>\n",
       "      <td>way</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>DT</td>\n",
       "      <td>RB</td>\n",
       "      <td>:</td>\n",
       "      <td>DT</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>IN</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag type</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADV</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1    2    3      4      5      6        7       8  \\\n",
       "Word      Happy  families  are  all  alike      ;  every  unhappy  family   \n",
       "POS tag      JJ       NNS  VBP   DT     RB      :     DT       JJ      NN   \n",
       "Tag type    ADJ      NOUN  AUX  DET    ADV  PUNCT    DET      ADJ    NOUN   \n",
       "\n",
       "            9       10   11    12   13    14     15  \n",
       "Word       is  unhappy   in   its  own   way      .  \n",
       "POS tag   VBZ       JJ   IN  PRP$   JJ    NN      .  \n",
       "Tag type  AUX      ADJ  ADP   DET  ADJ  NOUN  PUNCT  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_POS_tag(sample_sentences[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>US</td>\n",
       "      <td>unveils</td>\n",
       "      <td>world</td>\n",
       "      <td>'s</td>\n",
       "      <td>most</td>\n",
       "      <td>powerful</td>\n",
       "      <td>supercomputer</td>\n",
       "      <td>,</td>\n",
       "      <td>beats</td>\n",
       "      <td>China</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>NNP</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>POS</td>\n",
       "      <td>RBS</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>,</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>NNP</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1      2    3     4         5              6  7      8  \\\n",
       "Word      US  unveils  world   's  most  powerful  supercomputer  ,  beats   \n",
       "POS tag  NNP       JJ     NN  POS   RBS        JJ             NN  ,    VBZ   \n",
       "\n",
       "             9 10  \n",
       "Word     China  .  \n",
       "POS tag    NNP  .  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagging with nltk\n",
    "import nltk\n",
    "nltk_pos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "pd.DataFrame(nltk_pos_tagged, columns=['Word', 'POS tag']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Happy</td>\n",
       "      <td>families</td>\n",
       "      <td>are</td>\n",
       "      <td>all</td>\n",
       "      <td>alike</td>\n",
       "      <td>;</td>\n",
       "      <td>every</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>family</td>\n",
       "      <td>is</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>in</td>\n",
       "      <td>its</td>\n",
       "      <td>own</td>\n",
       "      <td>way</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>DT</td>\n",
       "      <td>RB</td>\n",
       "      <td>:</td>\n",
       "      <td>DT</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>IN</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1    2    3      4  5      6        7       8    9  \\\n",
       "Word     Happy  families  are  all  alike  ;  every  unhappy  family   is   \n",
       "POS tag     JJ       NNS  VBP   DT     RB  :     DT       JJ      NN  VBZ   \n",
       "\n",
       "              10  11    12   13   14 15  \n",
       "Word     unhappy  in   its  own  way  .  \n",
       "POS tag       JJ  IN  PRP$   JJ   NN  .  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_pos_tagged = nltk.pos_tag(nltk.word_tokenize(sample_sentences[0]))\n",
    "pd.DataFrame(nltk_pos_tagged, columns=['Word', 'POS tag']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output gives us tags that purely follow the Penn Treebank format specifying the specific form of adjective, noun, or verbs in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building POS Taggers - only if necessary - otherwise use default NLTK or SpaCy\n",
    "We will be leveraging NLTK and spaCy, which use the Penn Treebank notation for POS tagging. Let’s look at how POS tagging can be implemented using spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore some techniques to build our own POS taggers! We leverage some classes provided by NLTK. To evaluate the performance of our taggers, we use some test data from the treebank corpus in NLTK. We will also be using some training data for training some of our taggers. To start with, we will first get the necessary data for training and evaluating the taggers by reading in the tagged treebank corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "data = treebank.tagged_sents()\n",
    "train_data = data[:3500]\n",
    "test_data = data[3500:]\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the test data to evaluate our taggers and see how they work on our sample sentence by using its tokens as input.\n",
    "\n",
    "We will first look at the DefaultTagger, which inherits from the SequentialBackoffTagger base class and assigns the same user input POS tag to each word. This might seem to be really naïve but it is an excellent way to form a baseline POS tagger and improve upon it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1454158195372253"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default tagger\n",
    "from nltk.tag import DefaultTagger\n",
    "dt = DefaultTagger('NN')\n",
    "# accuracy on test data\n",
    "dt.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('US', 'NN'),\n",
       " ('unveils', 'NN'),\n",
       " ('world', 'NN'),\n",
       " (\"'s\", 'NN'),\n",
       " ('most', 'NN'),\n",
       " ('powerful', 'NN'),\n",
       " ('supercomputer', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('beats', 'NN'),\n",
       " ('China', 'NN'),\n",
       " ('.', 'NN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging our sample headline\n",
    "dt.tag(nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this output we have obtained 14% accuracy in correctly tagging words from the treebank test dataset, which is not great. \n",
    "\n",
    "We will now use regular expressions and the RegexpTagger to see if we can build a better performing tagger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex tagger\n",
    "from nltk.tag import RegexpTagger\n",
    "# define regex tag patterns\n",
    "patterns = [\n",
    "        (r'.*ing$', 'VBG'),               # gerunds\n",
    "        (r'.*ed$', 'VBD'),                # simple past\n",
    "        (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "        (r'.*ould$', 'MD'),               # modals\n",
    "        (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "        (r'.*s$', 'NNS'),                 # plural nouns\n",
    "        (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "        (r'.*', 'NN')                     # nouns (default) ...\n",
    "]\n",
    "rt = RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24039113176493368"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('US', 'NN'),\n",
       " ('unveils', 'NNS'),\n",
       " ('world', 'NN'),\n",
       " (\"'s\", 'NN$'),\n",
       " ('most', 'NN'),\n",
       " ('powerful', 'NN'),\n",
       " ('supercomputer', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('beats', 'NNS'),\n",
       " ('China', 'NN'),\n",
       " ('.', 'NN')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.tag(nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output shows us that the accuracy has now increased to 24%, but can we do better? We will now train some n-gram taggers. \n",
    "\n",
    "We will use the train_data as training data to train the n-gram taggers based on sentence tokens and their POS tags. Then we will evaluate the trained taggers on test_data and see the result upon tagging our sample sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8607803272340013\n",
      "[('US', 'NNP'), ('unveils', None), ('world', 'NN'), (\"'s\", 'POS'), ('most', 'JJS'), ('powerful', 'JJ'), ('supercomputer', 'NN'), (',', ','), ('beats', None), ('China', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "## N gram taggers\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "\n",
    "ut = UnigramTagger(train_data)\n",
    "bt = BigramTagger(train_data)\n",
    "tt = TrigramTagger(train_data)\n",
    "\n",
    "# testing performance of unigram tagger\n",
    "print(ut.evaluate(test_data))\n",
    "print(ut.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13466937748087907\n",
      "[('US', None), ('unveils', None), ('world', None), (\"'s\", None), ('most', None), ('powerful', None), ('supercomputer', None), (',', None), ('beats', None), ('China', None), ('.', None)]\n"
     ]
    }
   ],
   "source": [
    "# testing performance of bigram tagger\n",
    "print(bt.evaluate(test_data))\n",
    "print(bt.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08064672281924679\n",
      "[('US', None), ('unveils', None), ('world', None), (\"'s\", None), ('most', None), ('powerful', None), ('supercomputer', None), (',', None), ('beats', None), ('China', None), ('.', None)]\n"
     ]
    }
   ],
   "source": [
    "# testing performance of trigram tagger\n",
    "print(tt.evaluate(test_data))\n",
    "print(tt.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output clearly shows us that we obtain 86% accuracy on the test set using unigram tagger alone, which is really good compared to our last tagger. \n",
    "\n",
    " Accuracies of the bigram and trigram models are far lower because the same bigrams and trigrams observed in the training data aren’t always present in the same way in the testing data.\n",
    " \n",
    " We now look at an approach to combine all the taggers by creating a combined tagger with a list of taggers and use a backoff tagger. Essentially, we would create a chain of taggers and each tagger would fall back on a backoff tagger if it cannot tag the input tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094781682641108\n",
      "[('US', 'NNP'), ('unveils', 'NNS'), ('world', 'NN'), (\"'s\", 'POS'), ('most', 'RBS'), ('powerful', 'JJ'), ('supercomputer', 'NN'), (',', ','), ('beats', 'NNS'), ('China', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def combined_tagger(train_data, taggers, backoff=None):\n",
    "    for tagger in taggers:\n",
    "        backoff = tagger(train_data, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "ct = combined_tagger(train_data=train_data,\n",
    "                     taggers=[UnigramTagger, BigramTagger, TrigramTagger],\n",
    "                     backoff=rt)\n",
    "# evaluating the new combined tagger with backoff taggers\n",
    "print(ct.evaluate(test_data))\n",
    "print(ct.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now obtain an accuracy of 91% on the test data, which is excellent. Also we see that this new tagger can successfully tag all the tokens in our sample sentence (even though a couple of them are not correct, like beats should be a verb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our final tagger, we will use a <b>supervised classification algorithm</b> to train our tagger. The ClassifierBasedPOSTagger class enables us train a tagger by using a supervised learning algorithm in the classifier_builder parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9306806079969019\n",
      "[('US', 'PRP'), ('unveils', 'VBZ'), ('world', 'VBN'), (\"'s\", 'POS'), ('most', 'JJS'), ('powerful', 'JJ'), ('supercomputer', 'NN'), (',', ','), ('beats', 'VBZ'), ('China', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
    "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
    "\n",
    "nbt = ClassifierBasedPOSTagger(train=train_data,\n",
    "                               classifier_builder=NaiveBayesClassifier.train)\n",
    "\n",
    "# evaluate tagger on test data and sample sentence\n",
    "print(nbt.evaluate(test_data))\n",
    "print(nbt.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this tagger, we get an accuracy of 93% on our test data, which is the highest out of all our taggers. Also if you observe the output tags for the sample sentence, you will see they are correct and make perfect sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
